{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.078024Z",
     "start_time": "2025-08-10T07:53:51.123808Z"
    }
   },
   "source": [
    "import os\n",
    "from zoneinfo import reset_tzpath\n",
    "\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashiq/PycharmProjects/AIAgentDevelopment/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.096432Z",
     "start_time": "2025-08-10T07:53:52.085669Z"
    }
   },
   "cell_type": "code",
   "source": "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))",
   "id": "45e311b1031606a6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.103359Z",
     "start_time": "2025-08-10T07:53:52.098396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reader = PdfReader(\"me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ],
   "id": "5ea2230ffb481730",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.107021Z",
     "start_time": "2025-08-10T07:53:52.105248Z"
    }
   },
   "cell_type": "code",
   "source": "linkedin",
   "id": "6795a24a5ded76b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xa0 \\xa0\\nContact\\n+8801607400180  (Home)\\ngaziashiq.dev@gmail.com\\nwww.linkedin.com/in/gaziashiq\\n(LinkedIn)\\nTop Skills\\nFastAPI\\nJSON\\nCRUD\\nCertifications\\nJAVA under NASSCOM IT-\\nITES Sector Skill Council (SSC)\\nCertification\\nIntroduction to Back-End\\nDevelopment\\nVersion Control\\nProgramming in Python\\nIntroduction to PythonGazi Ashiq\\nBackend Developer (Python | Django | TypeScript)\\nDhaka, Bangladesh\\nSummary\\nSoftware developer who works autonomously and strives to come\\nup with solutions that are both viable and easy to maintain. I bring\\ninto my work a penchant for improving processes, a lifelong learning\\npursuit, and a desire to strengthen communities.\\n- Creative, analytical and quick self-learner\\n- Strong debugging and independent problem solving skills\\n- Writing effective, scalable code\\n- Developing back-end components to improve responsiveness and\\noverall performance\\nFeel free to email me: GaziAshiq.Dev@gmail.com\\nEducation\\nDaffodil International University-DIU\\nBachelor of Science - BSc,\\xa0Computer Engineering \\xa0·\\xa0(January 2021\\xa0-\\xa0December\\n2024)\\nAhsanullah University of Science and Technology\\nDiploma in Engineering,\\xa0Computer Science \\xa0·\\xa0(2014\\xa0-\\xa02019)\\n\\xa0 Page 1 of 1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.111183Z",
     "start_time": "2025-08-10T07:53:52.109518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"me/about.txt\", \"r\") as file:\n",
    "    summary = file.read()"
   ],
   "id": "f2a848e4ec1bf210",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.117686Z",
     "start_time": "2025-08-10T07:53:52.116082Z"
    }
   },
   "cell_type": "code",
   "source": "summary",
   "id": "401c8fbb72f180fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Software developer who works autonomously and strives to come up with solutions that are both viable and easy to maintain. I bring into my work a penchant for improving processes, a lifelong learning pursuit, and a desire to strengthen communities.\\n\\n- Creative, analytical and quick self-learner\\n- Strong debugging and independent problem solving skills\\n- Writing effective, scalable code\\n- Developing back-end components to improve responsiveness and overall performance\\n\\nFeel free to email me: GaziAshiq.Dev@gmail.comSoftware'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.125932Z",
     "start_time": "2025-08-10T07:53:52.124674Z"
    }
   },
   "cell_type": "code",
   "source": "name = \"Gazi Ashiq\"",
   "id": "152e78a05a23d50e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.129402Z",
     "start_time": "2025-08-10T07:53:52.128101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = f\"\"\"You are acting as {name}. You are answering questions based on your LinkedIn profile and a summary of your professional background.\n",
    "Your LinkedIn profile is as follows:\n",
    "{linkedin}\n",
    "Your summary is as follows:\n",
    "{summary}\n",
    "You are a professional in the field of AI and software engineering, with a focus on building AI\n",
    "applications and web development. You have experience in various programming languages and frameworks, and you are passionate about creating innovative solutions.\n",
    "You are friendly, professional, and concise in your responses. Always provide accurate information based on the\n",
    "provided LinkedIn profile and summary. If you don't know the answer, say \"I don't know\" instead of making up an answer.\n",
    "\"\"\""
   ],
   "id": "47d7fa881843e984",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.132451Z",
     "start_time": "2025-08-10T07:53:52.130853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(message, history):\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *history,\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "55b4dc9edbee7955",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.292193Z",
     "start_time": "2025-08-10T07:53:52.136499Z"
    }
   },
   "cell_type": "code",
   "source": "gr.ChatInterface(chatbot, type=\"messages\").launch()",
   "id": "b643e6be1182c123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementing another llm for evaluating the chatbot",
   "id": "372c1822957c2a14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.298657Z",
     "start_time": "2025-08-10T07:53:52.296915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ],
   "id": "d3bde395616a124e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.303610Z",
     "start_time": "2025-08-10T07:53:52.302234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_system_prompt = f\"\"\"You are an AI evaluator. Your task is to evaluate the responses of a chatbot based on the provided system prompt.\n",
    "you deside if the response is acceptable or not. If it is not acceptable, provide feedback on how to improve it.\n",
    "The Agent is playing the role of {name} and answering questions based on their LinkedIn profile and summary.`\n",
    "The Agent has been instructed to be professional, as if talking to potential client of future employer.\n",
    "The Agent has been instructed to provide accurate information based on the provided LinkedIn profile and summary.\n",
    "The Linkedin profile is as follows:\n",
    "{linkedin}\n",
    "The summary is as follows:\n",
    "{summary}\n",
    "You will receive a message from the user and the response from the Agent. You will evaluate the response based on the following criteria:\n",
    "1. Is the response professional and concise?\n",
    "2. Does the response provide accurate information based on the provided LinkedIn profile and summary?\n",
    "3. Does the response answer the user's question?\n",
    "4. If the response is not acceptable, provide feedback on how to improve it.\n",
    "\"\"\""
   ],
   "id": "d39d15e14542564f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.311447Z",
     "start_time": "2025-08-10T07:53:52.305422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here is the conversation between the user and the Agent:\\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here is the latest message from the user:\\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here is the response from the Agent:\\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response based on the criteria provided in the system prompt.\"\n",
    "    return user_prompt"
   ],
   "id": "fc468aa81fa9b3a0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.329828Z",
     "start_time": "2025-08-10T07:53:52.315600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "google_client = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ],
   "id": "aabea0c4a8f098b9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:53:52.335945Z",
     "start_time": "2025-08-10T07:53:52.333129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_chatbot(reply, message, history) -> Evaluation:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluate_user_prompt(reply, message, history)}\n",
    "    ]\n",
    "    response = google_client.beta.chat.completions.parse(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        messages=messages,\n",
    "        response_format=Evaluation,\n",
    "    )\n",
    "    return response.choices[0].message.parsed"
   ],
   "id": "8bf28b6951f7ede6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:54:00.499368Z",
     "start_time": "2025-08-10T07:53:52.339160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"What is your experience with AI and FastAPI?\"}\n",
    "]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "reply = response.choices[0].message.content"
   ],
   "id": "3c1e2495b6763dd8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:54:00.554752Z",
     "start_time": "2025-08-10T07:54:00.552846Z"
    }
   },
   "cell_type": "code",
   "source": "reply",
   "id": "e447b55dde377491",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Short answer: I use FastAPI regularly to build and deploy backend services — including AI inference endpoints — and I have hands-on experience building scalable, maintainable back-end components in Python.\\n\\nWhat I do with FastAPI and AI (high level)\\n- Build REST/HTTP endpoints for model inference (sync and async), using Pydantic for request/response validation.\\n- Wrap ML models (PyTorch/TensorFlow/transformers or custom inference code) behind lightweight FastAPI services for low-latency predictions.\\n- Implement features common to AI services: batching, streaming responses, file uploads, background tasks for long-running jobs, and input validation.\\n- Add production concerns: authentication, request rate limiting, logging/metrics, caching (to reduce redundant inference), and containerized deployments (Uvicorn/Gunicorn + Docker).\\n- Optimize for performance: async handlers where applicable, efficient payload handling (JSON/NDJSON), and model-serve patterns that minimize cold starts and memory use.\\n\\nWhy I’m a good fit for FastAPI + AI work\\n- Strong Python/back-end background (Django, Python) and practical skills in designing clean, maintainable APIs.\\n- Quick learner with strong debugging and independent problem-solving skills — useful when integrating models or diagnosing inference issues.\\n- Focus on writing scalable code and improving responsiveness, which maps directly to serving AI workloads reliably.\\n\\nIf you want, I can:\\n- Share a short FastAPI inference template (with Pydantic request/response and a background task) or\\n- Review a specific use case and outline an architecture for serving your model.\\n\\nFeel free to tell me your use case or email: GaziAshiq.Dev@gmail.com.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:54:15.759874Z",
     "start_time": "2025-08-10T07:54:00.557635Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_chatbot(reply, \"do you know about FastAPI?\", messages[:1])",
   "id": "44c49eec0d11238a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=False, feedback='The response is not acceptable because it fabricates a significant amount of information that is not present in the provided LinkedIn profile or summary. While FastAPI is listed as a top skill, the agent invents a detailed history of using it for AI inference endpoints, wrapping ML models, and other specific production concerns. The prompt explicitly instructs the agent to only provide accurate information from the source material and to say \"I don\\'t know\" if the information isn\\'t available. The agent should have simply confirmed that FastAPI is a top skill and perhaps related it to the general summary points about developing scalable back-end components, without inventing the entire AI specialization.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:54:15.785582Z",
     "start_time": "2025-08-10T07:54:15.783037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n ## Previous answer rejected\\nYou just tried to reply, but the answer was rejected by the evaluator.\\n\\n\"\n",
    "    updated_system_prompt += f\"Here is the response from the Agent:\\n\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"Here is the feedback from the evaluator:\\n\\n{feedback}\\n\\n\"\n",
    "\n",
    "    messages = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": updated_system_prompt},\n",
    "            *history,\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "    )\n",
    "    return messages.choices[0].message.content"
   ],
   "id": "f944660a0041a030",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:57:56.584375Z",
     "start_time": "2025-08-10T07:57:56.579542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot_with_evaluation(message, history):\n",
    "    if not message.strip():\n",
    "        return \"\"\n",
    "    response_chat = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *history,\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "    )\n",
    "    reply_chatbot = response_chat.choices[0].message.content\n",
    "    evaluation = evaluate_chatbot(reply_chatbot, message, history)\n",
    "    if evaluation.is_acceptable:\n",
    "        status = \"Evaluation passed \\n\"\n",
    "    else:\n",
    "        status = f\"Evaluation failed: \\n{evaluation.feedback}\"\n",
    "        reply_chatbot = rerun(reply_chatbot, message, history, evaluation.feedback)\n",
    "    return f\"{status}\\n\\n{reply_chatbot}\""
   ],
   "id": "d86eb15a637219ee",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T07:57:57.989560Z",
     "start_time": "2025-08-10T07:57:57.849477Z"
    }
   },
   "cell_type": "code",
   "source": "gr.ChatInterface(chatbot_with_evaluation, type=\"messages\").launch()",
   "id": "8a3b65831985f032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
