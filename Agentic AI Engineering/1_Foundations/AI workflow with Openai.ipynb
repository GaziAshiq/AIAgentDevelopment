{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T11:55:13.196258Z",
     "start_time": "2025-08-06T11:55:13.162498Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    logger.error(\"OPENAI_API_KEY is not set in the environment variables.\")\n",
    "else:\n",
    "    logger.info(f\"OpenAI API exists: {openai_api_key[:10]}...\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-08-06 17:55:13.195\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mOpenAI API exists: sk-proj-Yq...\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T11:55:59.050185Z",
     "start_time": "2025-08-06T11:55:58.799258Z"
    }
   },
   "cell_type": "code",
   "source": "from openai import OpenAI",
   "id": "2e08c476e10faa8c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T11:57:57.832437Z",
     "start_time": "2025-08-06T11:57:57.794482Z"
    }
   },
   "cell_type": "code",
   "source": "openai_client = OpenAI()",
   "id": "d1d5f7b2c4a684a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T11:59:13.509825Z",
     "start_time": "2025-08-06T11:59:13.507217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is 4+3?\"\n",
    "    }\n",
    "]"
   ],
   "id": "fc8792c62df18991",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:02:13.823462Z",
     "start_time": "2025-08-06T12:02:12.273191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message,\n",
    "    max_tokens=50,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(response)"
   ],
   "id": "6de6aeb49c550b37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1X8PKDpwJs8HNq0iNdHTnaBr8w89', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='4 + 3 equals 7.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754481733, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=8, prompt_tokens=14, total_tokens=22, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:02:19.914565Z",
     "start_time": "2025-08-06T12:02:19.912263Z"
    }
   },
   "cell_type": "code",
   "source": "print(response.choices[0].message.content)",
   "id": "904438ab980e8241",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 + 3 equals 7.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:13:27.533356Z",
     "start_time": "2025-08-06T12:13:26.273308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let's ask a question\n",
    "query = \"Please propose a hard , challenging question to assess my knowledge of AI. Respond only with the question, no other text.\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ],
   "id": "3548bd8e9a90f4ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the key differences between reinforcement learning and supervised learning, and can you provide an example where reinforcement learning would be more appropriate than supervised learning?\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:13:49.721869Z",
     "start_time": "2025-08-06T12:13:36.717980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ask it again, for the answer\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": question}]\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ],
   "id": "c7e6397ff8e1ffd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcement learning (RL) and supervised learning (SL) are two fundamental paradigms in machine learning, each suited for different types of problems. Here are the key differences between them:\n",
      "\n",
      "### Key Differences:\n",
      "\n",
      "1. **Learning Paradigm**:\n",
      "   - **Supervised Learning**: The model learns from a labeled dataset, where each input sample has a corresponding output label. The objective is to learn a mapping from inputs to outputs based on these labels.\n",
      "   - **Reinforcement Learning**: The model (agent) learns to make decisions by interacting with an environment, receiving feedback in the form of rewards or penalties based on its actions. The objective is to learn a policy that maximizes cumulative rewards over time.\n",
      "\n",
      "2. **Nature of Feedback**:\n",
      "   - **Supervised Learning**: The feedback is explicit and direct (i.e., correct labels or outputs are provided).\n",
      "   - **Reinforcement Learning**: The feedback is indirect and delayed. The agent may receive rewards only after several actions, making it more complicated to associate specific actions with the received rewards.\n",
      "\n",
      "3. **Problem Structure**:\n",
      "   - **Supervised Learning**: Problems are typically static, with a fixed set of input-output pairs. It involves predicting outcomes based on existing data.\n",
      "   - **Reinforcement Learning**: Problems are dynamic and sequential, where the agent's current actions can affect future states and available actions.\n",
      "\n",
      "4. **Objective**:\n",
      "   - **Supervised Learning**: Aim is to minimize a loss function that quantifies the difference between predicted and actual outputs.\n",
      "   - **Reinforcement Learning**: Aim is to maximize the expected cumulative reward, balancing the exploration (trying new actions) and exploitation (choosing known rewarding actions).\n",
      "\n",
      "### Example Where Reinforcement Learning is More Appropriate:\n",
      "\n",
      "**Example: Video Game Playing**\n",
      "\n",
      "In a video game, an agent (the player) controls a character that needs to navigate through various challenges to achieve the goal of winning the game. Hereâ€™s why reinforcement learning is more suitable for this scenario:\n",
      "\n",
      "- **Dynamic Environment**: The game environment changes based on the agent's actions (e.g., enemies spawn or move), creating a dynamic setting that RL is designed to handle.\n",
      "- **Delayed Rewards**: The agent does not receive immediate feedback after each action. For instance, the agent may only learn it has won or lost after completing a level, which requires understanding the consequences of a sequence of actions.\n",
      "- **Exploration vs. Exploitation**: The agent must balance exploring new strategies and moves (like trying to find new paths or strategies) with exploiting known successful strategies to win the game.\n",
      "\n",
      "In contrast, using supervised learning would not be feasible here, as the agent cannot learn from historical labeled data indicating the optimal actions since the outcomes are inherently uncertain and sequential. Instead, RL enables the agent to learn optimal strategies through trial and error in a manner that is well-suited to the complex nature of gaming environments.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:15:55.966361Z",
     "start_time": "2025-08-06T12:15:55.960568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(f\"**Question:** {question}\"))\n",
    "display(Markdown(f\"**Answer:** {answer}\"))"
   ],
   "id": "e168cd147407b05d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Question:** What are the key differences between reinforcement learning and supervised learning, and can you provide an example where reinforcement learning would be more appropriate than supervised learning?"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Answer:** Reinforcement learning (RL) and supervised learning (SL) are two fundamental paradigms in machine learning, each suited for different types of problems. Here are the key differences between them:\n\n### Key Differences:\n\n1. **Learning Paradigm**:\n   - **Supervised Learning**: The model learns from a labeled dataset, where each input sample has a corresponding output label. The objective is to learn a mapping from inputs to outputs based on these labels.\n   - **Reinforcement Learning**: The model (agent) learns to make decisions by interacting with an environment, receiving feedback in the form of rewards or penalties based on its actions. The objective is to learn a policy that maximizes cumulative rewards over time.\n\n2. **Nature of Feedback**:\n   - **Supervised Learning**: The feedback is explicit and direct (i.e., correct labels or outputs are provided).\n   - **Reinforcement Learning**: The feedback is indirect and delayed. The agent may receive rewards only after several actions, making it more complicated to associate specific actions with the received rewards.\n\n3. **Problem Structure**:\n   - **Supervised Learning**: Problems are typically static, with a fixed set of input-output pairs. It involves predicting outcomes based on existing data.\n   - **Reinforcement Learning**: Problems are dynamic and sequential, where the agent's current actions can affect future states and available actions.\n\n4. **Objective**:\n   - **Supervised Learning**: Aim is to minimize a loss function that quantifies the difference between predicted and actual outputs.\n   - **Reinforcement Learning**: Aim is to maximize the expected cumulative reward, balancing the exploration (trying new actions) and exploitation (choosing known rewarding actions).\n\n### Example Where Reinforcement Learning is More Appropriate:\n\n**Example: Video Game Playing**\n\nIn a video game, an agent (the player) controls a character that needs to navigate through various challenges to achieve the goal of winning the game. Hereâ€™s why reinforcement learning is more suitable for this scenario:\n\n- **Dynamic Environment**: The game environment changes based on the agent's actions (e.g., enemies spawn or move), creating a dynamic setting that RL is designed to handle.\n- **Delayed Rewards**: The agent does not receive immediate feedback after each action. For instance, the agent may only learn it has won or lost after completing a level, which requires understanding the consequences of a sequence of actions.\n- **Exploration vs. Exploitation**: The agent must balance exploring new strategies and moves (like trying to find new paths or strategies) with exploiting known successful strategies to win the game.\n\nIn contrast, using supervised learning would not be feasible here, as the agent cannot learn from historical labeled data indicating the optimal actions since the outcomes are inherently uncertain and sequential. Instead, RL enables the agent to learn optimal strategies through trial and error in a manner that is well-suited to the complex nature of gaming environments."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise",
   "id": "18b17da591165a14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:19:16.859478Z",
     "start_time": "2025-08-06T12:19:15.186902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"give me a business area that might worth to explore\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message,\n",
    "    max_tokens=50,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "business_area = response.choices[0].message.content\n",
    "display(Markdown(f\"**Business Area:** {business_area}\"))"
   ],
   "id": "fef06b1cb431d06d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Business Area:** One promising business area worth exploring is **sustainable packaging solutions**. As consumers become increasingly aware of environmental issues, there is a growing demand for eco-friendly packaging options across various industries, including food and beverage, e-commerce, and consumer goods. \n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:20:04.622358Z",
     "start_time": "2025-08-06T12:19:55.255270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"what are the top 3 challenges in {business_area}?\"\n",
    "    }\n",
    "]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message,\n",
    "    temperature=0.7,\n",
    ")\n",
    "challenges = response.choices[0].message.content\n",
    "display(Markdown(f\"**Challenges:** {challenges}\"))"
   ],
   "id": "585be664ebbc4045",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Challenges:** Exploring the sustainable packaging solutions sector presents several opportunities but also comes with notable challenges. Here are the top three challenges in this promising business area:\n\n1. **Material Innovation and Sourcing**: \n   - Developing sustainable packaging materials that are both eco-friendly and functional can be complex. Many traditional materials, such as plastics, offer durability and versatility that newer sustainable alternatives may not match. Innovating new materials (e.g., biodegradable, compostable, or recyclable options) requires significant research and development investment. Additionally, sourcing sustainable raw materials can be challenging, as they may be more expensive or less readily available than conventional materials, impacting overall production costs.\n\n2. **Regulatory Compliance and Standards**: \n   - The sustainable packaging industry must navigate a complex landscape of regulations and standards that vary by region and industry. Compliance with environmental regulations, labeling requirements, and certification processes can be time-consuming and costly. Furthermore, as the sustainability landscape evolves, keeping up with changing regulations and ensuring that products meet both consumer expectations and legal standards can pose a significant challenge for businesses.\n\n3. **Consumer Education and Market Acceptance**: \n   - While there is a rising demand for sustainable packaging, many consumers may not fully understand the benefits or proper disposal methods for eco-friendly options. Companies must invest in consumer education to ensure that their sustainable packaging solutions are embraced rather than dismissed due to misconceptions. Additionally, businesses need to balance sustainability with cost-effectiveness and convenience, as consumers may be hesitant to adopt products that are perceived as less functional or more expensive.\n\nAddressing these challenges will require collaboration across industries, innovation in material science, and effective marketing strategies to educate consumers and encourage the adoption of sustainable packaging solutions."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:21:41.720400Z",
     "start_time": "2025-08-06T12:21:24.456171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"propose the Agentic AI solution for the {business_area}?\"\n",
    "    }\n",
    "]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message,\n",
    "    temperature=0.7,\n",
    ")\n",
    "solution = response.choices[0].message.content\n",
    "display(Markdown(f\"**Solution:** {solution}\"))"
   ],
   "id": "11255dafd24403a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Solution:** **Agentic AI Solution for Sustainable Packaging Solutions**\n\n**Overview:**\nThe proposed Agentic AI solution leverages artificial intelligence to facilitate the development, production, and distribution of sustainable packaging. By using AI-driven insights, businesses can optimize their packaging processes to reduce waste, enhance recyclability, and improve overall sustainability while meeting consumer demands.\n\n### Key Components of the Agentic AI Solution:\n\n1. **Data-Driven Material Selection:**\n   - **AI Algorithms:** Utilize machine learning algorithms to analyze data on various materials, their environmental impact, and lifecycle assessments.\n   - **Material Database:** Create a comprehensive database of sustainable materials, including biodegradable plastics, recycled paper, and plant-based options, to guide businesses in selecting the most eco-friendly options for their packaging needs.\n\n2. **Design Optimization:**\n   - **Generative Design Tools:** Employ generative design algorithms that can create innovative packaging designs that minimize material usage while maximizing protection and functionality.\n   - **Consumer-Centric Designs:** Use AI to analyze consumer preferences and trends, ensuring that packaging designs are not only sustainable but also appealing to the target market.\n\n3. **Supply Chain Optimization:**\n   - **Predictive Analytics:** Implement predictive analytics to forecast demand and optimize inventory management for sustainable packaging materials. This can help reduce waste and ensure efficient production cycles.\n   - **Supplier Matching:** Use AI to match businesses with suppliers who provide sustainable materials, ensuring a lower carbon footprint throughout the supply chain.\n\n4. **Lifecycle Assessment and Impact Tracking:**\n   - **AI-Driven Impact Analysis:** Develop tools that allow businesses to conduct real-time lifecycle assessments of their packaging options, providing insights into carbon footprint, recyclability, and overall environmental impact.\n   - **Feedback Loop:** Incorporate user feedback and environmental data to continuously improve packaging solutions and track progress against sustainability goals.\n\n5. **Consumer Engagement and Education:**\n   - **Personalized Marketing:** Use AI to create targeted campaigns that educate consumers about the benefits of sustainable packaging, fostering brand loyalty and increasing market share.\n   - **Interactive Platforms:** Develop platforms that allow consumers to learn about the sustainability of packaging options, encouraging them to make informed choices and engage with brands committed to eco-friendliness.\n\n6. **Regulatory Compliance and Reporting:**\n   - **Compliance Checker:** Implement AI tools that help businesses navigate the complex landscape of environmental regulations, ensuring that their packaging solutions meet legal requirements.\n   - **Automated Reporting:** Use AI to automate the reporting process, making it easier for businesses to document and communicate their sustainability initiatives to stakeholders and consumers.\n\n### Implementation Strategy:\n\n1. **Partnerships with Industry Leaders:**\n   - Collaborate with manufacturers, packaging designers, and sustainability experts to ensure the AI solution meets industry standards and leverages the latest innovations in sustainable materials.\n\n2. **Pilot Programs:**\n   - Launch pilot programs with select businesses to test the AI solution, gather feedback, and refine the technology before a broader rollout.\n\n3. **Continuous Learning:**\n   - Establish a feedback loop where the AI system continuously learns from new data, consumer preferences, and emerging sustainable materials to stay ahead of market trends.\n\n4. **Marketing and Outreach:**\n   - Develop a strong marketing strategy to promote the benefits of the AI solution to potential clients and consumers, emphasizing the commitment to sustainability and environmental responsibility.\n\n### Conclusion:\nThe Agentic AI solution for sustainable packaging not only addresses the growing consumer demand for eco-friendly options but also provides businesses with the tools they need to innovate and lead in sustainability. By integrating AI into the packaging process, companies can significantly reduce their environmental impact while enhancing their brand value and consumer trust."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf708027d4739e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
